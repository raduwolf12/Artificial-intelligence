{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.688762Z",
     "start_time": "2020-04-15T05:32:33.683775Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from typing import Tuple, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.703722Z",
     "start_time": "2020-04-15T05:32:33.694747Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the data from the file stored at :param path: and returns the \n",
    "    input values and the class labels.\n",
    "    :param path: path of a CVS file with data\n",
    "    :return: a tuple containing the input matrix of shape (n, p) and a line \n",
    "    vector with the m class labels in {0, ..., 9}\n",
    "    \"\"\"\n",
    "    # citire date sin fisierul dat de path\n",
    "    df = pd.read_csv(path,header=None)\n",
    "    X = df.values[:,1:].T\n",
    "    y = df.values[:,0].reshape(len(df),1).T\n",
    "    assert X.ndim ==  2, 'Matrix required for input values'\n",
    "    assert y.ndim == 2, 'Column matrix required for labels'\n",
    "    assert y.shape == (1, X.shape[1]), 'Same number of lines is required'\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.710703Z",
     "start_time": "2020-04-15T05:32:33.706715Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = './lab4/data/mnist_train.csv'\n",
    "path_test = './lab4/data/mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.182596Z",
     "start_time": "2020-04-15T05:32:33.713696Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_file(path_train)\n",
    "\n",
    "assert X_train.shape == (784, 60000)\n",
    "assert y_train.shape == (1, 60000)\n",
    "\n",
    "X_test, y_test = load_file(path_test)\n",
    "\n",
    "assert X_test.shape == (784, 10000)\n",
    "assert y_test.shape == (1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.194562Z",
     "start_time": "2020-04-15T05:32:38.184589Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_values(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Scales the values to range [0, 1].\n",
    "    :param X: an (m, n) matrix with values between 0 and 255.\n",
    "    :return: an (m, n) matrix containing values of :param X: scaled in [0, 1]\n",
    "    \"\"\"\n",
    "    result = X/255 # scrieti cod\n",
    "    assert 0 <= np.min(result) <= np.max(result) <= 1, 'Scaled values should be in [0, 1]'\n",
    "    assert X.shape == result.shape, 'Scaling preserves shape'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.531663Z",
     "start_time": "2020-04-15T05:32:38.203540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "X_test = scale_values(X_test)\n",
    "assert X_test.shape == (784, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:41:07.997557Z",
     "start_time": "2019-11-24T15:41:07.991110Z"
    }
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.541636Z",
     "start_time": "2020-04-15T05:32:38.535651Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 10 # number of classes\n",
    "n, p = X_train.shape\n",
    "architecture = [n, 100, m] # list: [input_size, hidden1, hidden2, ..., output_size]\n",
    "\n",
    "assert len(architecture) >= 3, 'At least one hidden layer'\n",
    "assert architecture[0] == n\n",
    "assert architecture[-1] == m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderile sunt initializate conform strategiei lui Xavier Glorot. Pentru o matrice de ponderi $W^{[l]}$ de forma $n_{l} \\times n_{l-1}$, ponderile pot fi initializate cu o distributie uniforma in intervalul \n",
    "$$\n",
    "\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}, +\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}\\right]\n",
    "$$\n",
    "\n",
    "Ponderile de bias se obisnuiesc a se initializa cu 0; intializarea aleatoare a ponderilor W este considerata suficienta pentru a obtine spargerea simetriei.\n",
    "\n",
    "Ref: [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.567564Z",
     "start_time": "2020-04-15T05:32:38.545624Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_weights(architecture: List[int], init_type:str='glorot_uniform') -> Tuple[List[np.array], List[np.array]]:\n",
    "    \"\"\"Creates the list of weights and biases for the given architecture.\n",
    "    :param architecture: list of number of nodes in each layer \n",
    "    (including input and ouotput layers)\n",
    "    :param init_type: name of initialization parameter. Defaults to \n",
    "    'glorot_uniform', add other supported initializtion strategies.\n",
    "    :return: a tuple containing: list of weight matrices W, a list of bias \n",
    "    column vectors. The two lists have the same numer of elements, number of \n",
    "    layers - 1.\n",
    "    \"\"\"\n",
    "    L = len(architecture)\n",
    "    W, b = [], []\n",
    "    # initializare de ponderi\n",
    "    for n_lplus1, nl in zip(architecture[1:], architecture[:-1]):\n",
    "        W.append(np.random.rand(n_lplus1,nl)* np.random.uniform(-1,1) *np.sqrt(6.0 / (nl + n_lplus1)))# scrieti cod\n",
    "    for n_l in architecture[1:]:\n",
    "        b.append(np.zeros((n_l,1))) # scrieti cod\n",
    "    assert len(W) == len(b) == L-1\n",
    "    for i, w in enumerate(W):\n",
    "        assert w.shape == (architecture[i+1], architecture[i]), f'Shape of W[{i}] should be ({L[i+1], L[i]})'\n",
    "    for i, _b in enumerate(b):\n",
    "        assert _b.shape == (architecture[i+1], 1), f'Shape of b[{i}] should be ({L[i+1]}, 1)'\n",
    "    if init_type == 'glorot_uniform':\n",
    "        for i, w in enumerate(W):\n",
    "            w_shape_sum = np.sum(w.shape)\n",
    "            assert -np.sqrt(6)/np.sqrt(w_shape_sum) <= np.min(w) <= np.sqrt(6)/np.sqrt(w_shape_sum), f\"Values of W[{i}] should be according to Glorot's initialization\"\n",
    "        for i, _b in enumerate(b):\n",
    "            assert 0 == np.min(_b) == np.min(_b) == 0, f\"Values of b[{i}] should be initialized to 0\"\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.584519Z",
     "start_time": "2020-04-15T05:32:38.569559Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes sigmoid activation function\"\"\"\n",
    "    # scrieti cod\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def derivate_sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the sigmoid activation function\"\"\"\n",
    "    # scrieti cod\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the tanh activation function\"\"\"\n",
    "    # scrieti cod\n",
    "    return np.tanh(z)\n",
    "\n",
    "def derivate_tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the tanh activation function\"\"\"\n",
    "    # scrieti cod\n",
    "    return 1.0 - np.tanh(z)**2\n",
    "\n",
    "def ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the rectified linear unit activation function\"\"\"\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def derivative_ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives of the rectified linear unit activation function\"\"\"\n",
    "    # scrieti cod\n",
    "    z[z <= 0.0] = 0.0\n",
    "    z[z > 0.0] = 1.0\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.596496Z",
     "start_time": "2020-04-15T05:32:38.589506Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z, axis=0):\n",
    "    \"\"\"Applies softmax to a matrix z.\n",
    "    :param z: np.array of shape (m, k)\n",
    "    \"\"\"\n",
    "    # scrieti cod, posibil mai multe linii\n",
    "    result = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    assert np.allclose(np.sum(result, axis=axis), 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.609453Z",
     "start_time": "2020-04-15T05:32:38.599481Z"
    }
   },
   "outputs": [],
   "source": [
    "W, b = create_weights(architecture=architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:54:14.739424Z",
     "start_time": "2020-04-15T15:54:14.320545Z"
    }
   },
   "outputs": [],
   "source": [
    "def can_multiply(a:np.array, b:np.array) -> bool:\n",
    "    return a.ndim == b.ndim == 2 and a.shape[1] == b.shape[0]\n",
    "\n",
    "def can_multiply_hadamard(a:np.array, b:np.array) -> bool:\n",
    "    return a.shape == b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.636381Z",
     "start_time": "2020-04-15T05:32:38.624413Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(X:np.array, W:List[np.array], b:List[np.array], f:List[Callable]) -> np.array:\n",
    "    \"\"\"Computes the output produced by the MLP for the given input X\n",
    "    :param X: np.array of shape (n, p). Each column of X is a datum from a set.\n",
    "    :param W: a list of weight matrices\n",
    "    :param b: a list of bias columns\n",
    "    :param f: a list of activation functions\n",
    "    :return: a matrix of output values produced by MLP, of shape: number of \n",
    "    predicted outputs (e.g. classes), number of input vectors p\n",
    "    \"\"\"\n",
    "    assert len(W) == len(b) == len(f)\n",
    "    p = X.shape[1]\n",
    "    a = X\n",
    "    for i, (_w, _b, _f) in enumerate(zip(W, b, f)):\n",
    "        # variabila i poate fi folosita pentru debug\n",
    "        assert can_multiply(_w, a)\n",
    "        z = np.dot(_w, a) + _b # scrieti cod\n",
    "        assert z.shape == (_w.shape[0], p)\n",
    "        a = _f(z) # scrieti cod\n",
    "        assert a.shape == z.shape\n",
    "    assert a.shape == (W[-1].shape[0], p)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.852801Z",
     "start_time": "2020-04-15T05:32:38.639373Z"
    }
   },
   "outputs": [],
   "source": [
    "# f[0] = functia de activare pe primul strat ascuns; \n",
    "# f[1] = functia de activare pe al doilea strat ascuns etc.\n",
    "f = [sigmoid, softmax] \n",
    "y_hat = model(X_train, W, b, f)\n",
    "\n",
    "assert y_hat.shape == (m, p)\n",
    "assert np.allclose(y_hat.sum(axis=0), np.ones(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:44.535803Z",
     "start_time": "2020-04-15T05:32:44.527825Z"
    }
   },
   "outputs": [],
   "source": [
    "def J(X, y, W, b, f, num_classes=10, _lambda=0.01):\n",
    "    \"\"\"Computes the error function for MLP\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k)\n",
    "    :param W: list pf MLPs weights\n",
    "    :param b: list pf MLPs biases\n",
    "    :return: loss values, composed of cross entropy + penalty term\n",
    "    \"\"\"\n",
    "    p = X.shape[1]\n",
    "    EPS = 1e-5\n",
    "    # computes a one hot encoding for the given classes:\n",
    "    # if y[i]=c, 0 <= c <= 9 (here), then column i in one_hot_encoding is filled\n",
    "    # in with 0, excepting line c where one finds value 1\n",
    "    if y.shape[0] == 1 :\n",
    "        one_hot_encoding = np.zeros((p,num_classes))\n",
    "        one_hot_encoding[np.arange(y.shape[1]), y] = 1\n",
    "        one_hot_encoding = one_hot_encoding.T\n",
    "        y= one_hot_encoding\n",
    "        assert np.allclose(one_hot_encoding.sum(axis=0), np.ones(p))    \n",
    "    assert np.allclose(y.sum(axis=0), np.ones(p))   \n",
    "    predicted = model(X, W, b, f)\n",
    "    predicted = np.clip(predicted, EPS, 1-EPS)\n",
    "    loss1 = -(1.0 / p) *np.sum(np.multiply(np.log(predicted),y)) # scrieti cod \n",
    "    loss2 = + (_lambda / (2 * p)) * (LA.norm(W[0]) + LA.norm(W[1]))\n",
    "    return loss1 + loss2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.074986Z",
     "start_time": "2020-04-02T05:08:15.069005Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(X:np.array, y:np.array, W: List[np.array], b: List[np.array], f:List[Callable]) -> float:\n",
    "    \"\"\"Computes the accuracy on a given input dataset X, with ground truth y\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k); each value is the index of a class\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activation functions. the last one must be softmax\n",
    "    :return: ratio between correctly classified vectors and total number of cases\n",
    "    \"\"\"\n",
    "    y_hat = model(X,W,b,f)\n",
    "    y_predicted = np.expand_dims(np.argmax(y_hat, axis=0), axis=0) # scrieti cod\n",
    "    return (y_predicted == y).sum() / X.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back_propagation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X, y_hat, y, W, b, _lambda):  \n",
    "\n",
    "    z1 = np.dot(W[0], X) + b[0]\n",
    "    a1 = f[0](z1)\n",
    "\n",
    "    delta2 = (1.0 / X.shape[1]) * (y_hat - y)\n",
    "    delta_theta2 = np.dot(a1, delta2.T) + (_lambda / X.shape[1]) * W[1].T\n",
    "    delta_b2 = np.sum(delta2, axis=1, keepdims=True)\n",
    "    delta1 = np.dot(W[1].T, delta2) * derivate_sigmoid(a1)\n",
    "\n",
    "    delta_theta1 = np.dot(X, delta1.T) + (_lambda / X.shape[1]) * W[0].T\n",
    "    delta_b1 = np.sum(delta1, axis=1, keepdims=True)\n",
    "    return delta_theta2.T, delta_b2, delta_theta1.T, delta_b1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.098922Z",
     "start_time": "2020-04-02T05:08:15.078976Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array, num_classes, W: List[np.array],\n",
    "          b: List[np.array], f: List[Callable], _lambda: float, alpha: float, max_delta_error: float = 1e-4) -> Tuple[\n",
    "    List[np.array], List[np.array], List[float], List[float], List[float]]:\n",
    "    \"\"\"Runs the training on the training dataset (X, y). Stops when\n",
    "    difference between  two succesive error values is lower than :param max_delta_error:\n",
    "    :param X_train: np.array of shape (n, k), with training cases. Each column is a training case\n",
    "    :param y_train: np.array of shape (1, k), containing labels (0=class 0, ...)\n",
    "    :param X_test: np.array of shape (n, l), with test cases. Each column is a test vector\n",
    "    :param y_test: np.array of shape (1, l), containing labels (0=class 0, ...)\n",
    "    :param num_classes: number of classes\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activations functions; the last one must be softmax\n",
    "    :param _lambda: coefficient >= for the L2 penalty term\n",
    "    :param alpha: > 0, learning rate\n",
    "    :max_delta_error: >0, a threshold for max absolute difference of succesive loss values\n",
    "    :return: a tuple consisting of: list of weight matrices, list of biases, list of errors computed at each epoch on training set, 2 lists of accuracies on training and on test set at each epoch\n",
    "    \"\"\"\n",
    "    errors = [J(X_train, y_train, W, b, f, num_classes, _lambda)]\n",
    "    acc_train = [accuracy(X_train, y_train, W, b, f)]\n",
    "    acc_test = [accuracy(X_test, y_test, W, b, f)]\n",
    "    epoch = 0\n",
    "\n",
    "    iterations = X_train.shape[1] / batch_size\n",
    "    while True:\n",
    "        batch_loss = 0\n",
    "        epoch += 1\n",
    "        for it in range(int(iterations)):\n",
    "            X_batch = X_train[:, it * batch_size:(it + 1) * batch_size]\n",
    "\n",
    "            one_hot_encoding = np.zeros((X_train.shape[1], 10))\n",
    "            one_hot_encoding[np.arange(y_train.shape[1]), y_train] = 1\n",
    "            one_hot_encoding = one_hot_encoding.T\n",
    "            y_batch = one_hot_encoding[:, it * batch_size:(it + 1) * batch_size]\n",
    "\n",
    "            # actualizare ponderi si biases W, b pentru fiecare pereche de date din setul de instruire *_test\n",
    "            error = J(X_batch, y_batch, W, b, f, num_classes, _lambda)\n",
    "            batch_loss += error\n",
    "\n",
    "            y_hat = model(X_batch, W, b, f)\n",
    "            gradients = back_propagation(X_batch, y_hat, y_batch, W, b, _lambda)\n",
    "\n",
    "            W[1] = W[1] - alpha * gradients[0]\n",
    "            b[1] = b[1] - alpha * gradients[1]\n",
    "            W[0] = W[0] - alpha * gradients[2]\n",
    "            b[0] = b[0] - alpha * gradients[3]\n",
    "\n",
    "        error = batch_loss / iterations\n",
    "        errors.append(error)\n",
    "        train_acc = accuracy(X_train, y_train, W, b, f)  # scrieti cod\n",
    "        acc_train.append(train_acc)\n",
    "        test_acc = accuracy(X_test, y_test, W, b, f)  # scrieti cod\n",
    "        acc_test.append(test_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "        if np.abs(errors[-1] - errors[-2]) < max_delta_error:\n",
    "            break\n",
    "        test_loss = J(X_test, y_test, W, b, f, num_classes, _lambda)\n",
    "\n",
    "    return W, b, errors, acc_train, acc_test, test_loss  # scrieti cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:44:41.944041Z",
     "start_time": "2020-04-02T05:52:03.345797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, error: 2.2863598449825067, train accuracy: 0.6229, test accuracy: 0.6363\n",
      "Epoch: 2, error: 1.0332534143873402, train accuracy: 0.81775, test accuracy: 0.8188\n",
      "Epoch: 3, error: 0.6110243878561843, train accuracy: 0.8611, test accuracy: 0.8677\n",
      "Epoch: 4, error: 0.48688285129552666, train accuracy: 0.87975, test accuracy: 0.8842\n",
      "Epoch: 5, error: 0.4272897144587671, train accuracy: 0.8888166666666667, test accuracy: 0.8915\n",
      "Epoch: 6, error: 0.3923921819711388, train accuracy: 0.8952333333333333, test accuracy: 0.8984\n",
      "Epoch: 7, error: 0.3694537130266253, train accuracy: 0.8995166666666666, test accuracy: 0.9029\n",
      "Epoch: 8, error: 0.3531532851125286, train accuracy: 0.9026666666666666, test accuracy: 0.9058\n",
      "Epoch: 9, error: 0.34093470254539215, train accuracy: 0.9051666666666667, test accuracy: 0.9091\n",
      "Epoch: 10, error: 0.33141691076553453, train accuracy: 0.9070833333333334, test accuracy: 0.9108\n",
      "Epoch: 10, error: 0.33141691076553453, train accuracy: 0.9070833333333334, test accuracy: 0.9108\n",
      "Epoch: 11, error: 0.32378164750529365, train accuracy: 0.9088833333333334, test accuracy: 0.9124\n",
      "Epoch: 12, error: 0.31750513917595913, train accuracy: 0.9106666666666666, test accuracy: 0.914\n",
      "Epoch: 13, error: 0.3122416367891024, train accuracy: 0.9117833333333333, test accuracy: 0.9165\n",
      "Epoch: 14, error: 0.30774800392316126, train accuracy: 0.9130166666666667, test accuracy: 0.917\n",
      "Epoch: 15, error: 0.30385295683050767, train accuracy: 0.9140666666666667, test accuracy: 0.9181\n",
      "Epoch: 16, error: 0.3004328313917864, train accuracy: 0.915, test accuracy: 0.9186\n",
      "Epoch: 17, error: 0.29739678509479134, train accuracy: 0.9159333333333334, test accuracy: 0.9193\n",
      "Epoch: 18, error: 0.29467175222151065, train accuracy: 0.91655, test accuracy: 0.9198\n",
      "Epoch: 19, error: 0.2922061650064478, train accuracy: 0.91725, test accuracy: 0.9198\n",
      "Epoch: 20, error: 0.2899618310890338, train accuracy: 0.9178833333333334, test accuracy: 0.9205\n",
      "Epoch: 20, error: 0.2899618310890338, train accuracy: 0.9178833333333334, test accuracy: 0.9205\n",
      "Epoch: 21, error: 0.2879057076539526, train accuracy: 0.91865, test accuracy: 0.9213\n",
      "Epoch: 22, error: 0.28601115595872434, train accuracy: 0.9192666666666667, test accuracy: 0.9215\n",
      "Epoch: 23, error: 0.28425626135285326, train accuracy: 0.9198166666666666, test accuracy: 0.9225\n",
      "Epoch: 24, error: 0.28262440988720094, train accuracy: 0.9203333333333333, test accuracy: 0.923\n",
      "Epoch: 25, error: 0.28109965634381434, train accuracy: 0.9207666666666666, test accuracy: 0.9233\n",
      "Epoch: 26, error: 0.27967100562660646, train accuracy: 0.92095, test accuracy: 0.9238\n",
      "Epoch: 27, error: 0.278328181472378, train accuracy: 0.9214333333333333, test accuracy: 0.9234\n",
      "Epoch: 28, error: 0.2770620900789015, train accuracy: 0.9215833333333333, test accuracy: 0.9238\n",
      "Epoch: 29, error: 0.2758638680645578, train accuracy: 0.922, test accuracy: 0.9243\n",
      "Epoch: 30, error: 0.2747272449716913, train accuracy: 0.9222833333333333, test accuracy: 0.9246\n",
      "Epoch: 30, error: 0.2747272449716913, train accuracy: 0.9222833333333333, test accuracy: 0.9246\n",
      "Epoch: 31, error: 0.27364652382276805, train accuracy: 0.9225, test accuracy: 0.9246\n",
      "Epoch: 32, error: 0.2726156841763686, train accuracy: 0.92285, test accuracy: 0.9249\n",
      "Epoch: 33, error: 0.2716303670863346, train accuracy: 0.92315, test accuracy: 0.9249\n",
      "Epoch: 34, error: 0.2706865808371892, train accuracy: 0.9233, test accuracy: 0.9247\n",
      "Epoch: 35, error: 0.269780517994347, train accuracy: 0.92365, test accuracy: 0.9245\n",
      "Epoch: 36, error: 0.26890877162616145, train accuracy: 0.9237333333333333, test accuracy: 0.9247\n",
      "Epoch: 37, error: 0.26806828714176767, train accuracy: 0.92395, test accuracy: 0.9246\n",
      "Epoch: 38, error: 0.26725632035379104, train accuracy: 0.92415, test accuracy: 0.9245\n",
      "Epoch: 39, error: 0.2664704005617501, train accuracy: 0.92445, test accuracy: 0.925\n",
      "Epoch: 40, error: 0.2657082978390392, train accuracy: 0.9248166666666666, test accuracy: 0.9251\n",
      "Epoch: 40, error: 0.2657082978390392, train accuracy: 0.9248166666666666, test accuracy: 0.9251\n",
      "Epoch: 41, error: 0.2649675655655488, train accuracy: 0.9250333333333334, test accuracy: 0.9251\n",
      "Epoch: 42, error: 0.2642461498327621, train accuracy: 0.92515, test accuracy: 0.9251\n",
      "Epoch: 43, error: 0.26354300960814847, train accuracy: 0.9252833333333333, test accuracy: 0.9249\n",
      "Epoch: 44, error: 0.2628559174965613, train accuracy: 0.92545, test accuracy: 0.9247\n",
      "Epoch: 45, error: 0.2621841324884296, train accuracy: 0.9255666666666666, test accuracy: 0.9247\n",
      "Epoch: 46, error: 0.2615264620583186, train accuracy: 0.9257166666666666, test accuracy: 0.9246\n",
      "Epoch: 47, error: 0.2608814034695242, train accuracy: 0.926, test accuracy: 0.9249\n",
      "Epoch: 48, error: 0.2602474334311483, train accuracy: 0.92625, test accuracy: 0.9249\n",
      "Epoch: 49, error: 0.259624268363313, train accuracy: 0.9264166666666667, test accuracy: 0.9249\n",
      "Epoch: 50, error: 0.25901094732962393, train accuracy: 0.9266, test accuracy: 0.9247\n",
      "Epoch: 50, error: 0.25901094732962393, train accuracy: 0.9266, test accuracy: 0.9247\n",
      "Epoch: 51, error: 0.2584061870313732, train accuracy: 0.9267, test accuracy: 0.925\n",
      "Epoch: 52, error: 0.2578091257086413, train accuracy: 0.9267333333333333, test accuracy: 0.9253\n",
      "Epoch: 53, error: 0.2572194114366071, train accuracy: 0.9269333333333334, test accuracy: 0.9253\n",
      "Epoch: 54, error: 0.25663630368602175, train accuracy: 0.9269666666666667, test accuracy: 0.9255\n",
      "Epoch: 55, error: 0.2560591072115608, train accuracy: 0.9272, test accuracy: 0.9256\n",
      "Epoch: 56, error: 0.2554871695843008, train accuracy: 0.9272666666666667, test accuracy: 0.9257\n",
      "Epoch: 57, error: 0.25491987915688064, train accuracy: 0.92765, test accuracy: 0.9257\n",
      "Epoch: 58, error: 0.2543566633745751, train accuracy: 0.9276666666666666, test accuracy: 0.9259\n",
      "Epoch: 59, error: 0.25379698736242906, train accuracy: 0.9277666666666666, test accuracy: 0.9264\n",
      "Epoch: 60, error: 0.2532403527334353, train accuracy: 0.9280166666666667, test accuracy: 0.9264\n",
      "Epoch: 60, error: 0.2532403527334353, train accuracy: 0.9280166666666667, test accuracy: 0.9264\n",
      "Epoch: 61, error: 0.2526862965749289, train accuracy: 0.9280666666666667, test accuracy: 0.9264\n",
      "Epoch: 62, error: 0.2521343905796214, train accuracy: 0.9283, test accuracy: 0.9263\n",
      "Epoch: 63, error: 0.2515842402939256, train accuracy: 0.9284333333333333, test accuracy: 0.926\n",
      "Epoch: 64, error: 0.25103548445964513, train accuracy: 0.9286, test accuracy: 0.9261\n",
      "Epoch: 65, error: 0.2504877944262652, train accuracy: 0.9286166666666666, test accuracy: 0.9264\n",
      "Epoch: 66, error: 0.24994087361072856, train accuracy: 0.92875, test accuracy: 0.9263\n",
      "Epoch: 67, error: 0.24939377525734457, train accuracy: 0.9287666666666666, test accuracy: 0.9263\n",
      "Epoch: 68, error: 0.24884671139622655, train accuracy: 0.9290166666666667, test accuracy: 0.9262\n",
      "Epoch: 69, error: 0.24829967890260535, train accuracy: 0.9292333333333334, test accuracy: 0.9265\n",
      "Epoch: 70, error: 0.2477525067360959, train accuracy: 0.9293666666666667, test accuracy: 0.9268\n",
      "Epoch: 70, error: 0.2477525067360959, train accuracy: 0.9293666666666667, test accuracy: 0.9268\n",
      "Epoch: 71, error: 0.2472050531770779, train accuracy: 0.9294666666666667, test accuracy: 0.9267\n",
      "Epoch: 72, error: 0.2466572050772495, train accuracy: 0.9296666666666666, test accuracy: 0.9264\n",
      "Epoch: 73, error: 0.24610868631653898, train accuracy: 0.9298, test accuracy: 0.9264\n",
      "Epoch: 74, error: 0.2455594242196572, train accuracy: 0.93, test accuracy: 0.9266\n",
      "Epoch: 75, error: 0.2450095632188586, train accuracy: 0.93, test accuracy: 0.927\n",
      "Epoch: 76, error: 0.24445909599506702, train accuracy: 0.9300833333333334, test accuracy: 0.927\n",
      "Epoch: 77, error: 0.2439080391349716, train accuracy: 0.9303333333333333, test accuracy: 0.9273\n",
      "Epoch: 78, error: 0.24335616276121153, train accuracy: 0.93055, test accuracy: 0.9274\n",
      "Epoch: 79, error: 0.2428037773178086, train accuracy: 0.93055, test accuracy: 0.9275\n",
      "Epoch: 80, error: 0.24225057919465381, train accuracy: 0.9307, test accuracy: 0.9276\n",
      "Epoch: 80, error: 0.24225057919465381, train accuracy: 0.9307, test accuracy: 0.9276\n",
      "Epoch: 81, error: 0.24169702945404822, train accuracy: 0.9308166666666666, test accuracy: 0.9276\n",
      "Epoch: 82, error: 0.24114330653944685, train accuracy: 0.9309, test accuracy: 0.9275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, error: 0.24058933671588723, train accuracy: 0.9312333333333334, test accuracy: 0.9275\n",
      "Epoch: 84, error: 0.2400351696942091, train accuracy: 0.9313333333333333, test accuracy: 0.9275\n",
      "Epoch: 85, error: 0.23948128909813965, train accuracy: 0.9314666666666667, test accuracy: 0.9273\n",
      "Epoch: 86, error: 0.23892788262121803, train accuracy: 0.9318666666666666, test accuracy: 0.9271\n",
      "Epoch: 87, error: 0.2383751510847348, train accuracy: 0.9319333333333333, test accuracy: 0.9273\n",
      "Epoch: 88, error: 0.23782330718831007, train accuracy: 0.9320833333333334, test accuracy: 0.9275\n",
      "Epoch: 89, error: 0.2372725742643006, train accuracy: 0.9321333333333334, test accuracy: 0.9273\n",
      "Epoch: 90, error: 0.23672318504470538, train accuracy: 0.9322833333333334, test accuracy: 0.927\n",
      "Epoch: 90, error: 0.23672318504470538, train accuracy: 0.9322833333333334, test accuracy: 0.927\n",
      "Epoch: 91, error: 0.23617538043434838, train accuracy: 0.9323833333333333, test accuracy: 0.9273\n",
      "Epoch: 92, error: 0.235629408265657, train accuracy: 0.9324, test accuracy: 0.927\n",
      "Epoch: 93, error: 0.23508552198627602, train accuracy: 0.93245, test accuracy: 0.927\n",
      "Epoch: 94, error: 0.2345439792212355, train accuracy: 0.9325666666666667, test accuracy: 0.9273\n",
      "Epoch: 95, error: 0.23400504015443804, train accuracy: 0.9325166666666667, test accuracy: 0.9275\n",
      "Epoch: 96, error: 0.2334689656643866, train accuracy: 0.9325166666666667, test accuracy: 0.9276\n",
      "Epoch: 97, error: 0.2329359115635042, train accuracy: 0.9326666666666666, test accuracy: 0.928\n",
      "Epoch: 98, error: 0.23240581500131052, train accuracy: 0.9329333333333333, test accuracy: 0.928\n",
      "Epoch: 99, error: 0.2318793214980882, train accuracy: 0.9331166666666667, test accuracy: 0.9279\n",
      "Epoch: 100, error: 0.23135616817292953, train accuracy: 0.9332666666666667, test accuracy: 0.9287\n",
      "Epoch: 100, error: 0.23135616817292953, train accuracy: 0.9332666666666667, test accuracy: 0.9287\n",
      "Epoch: 101, error: 0.2308371118504128, train accuracy: 0.9334166666666667, test accuracy: 0.9288\n",
      "Epoch: 102, error: 0.23032233826442836, train accuracy: 0.93365, test accuracy: 0.9286\n",
      "Epoch: 103, error: 0.22981207613481916, train accuracy: 0.9336666666666666, test accuracy: 0.9287\n",
      "Epoch: 104, error: 0.22930650127955238, train accuracy: 0.9338166666666666, test accuracy: 0.9289\n",
      "Epoch: 105, error: 0.22880576724403606, train accuracy: 0.934, test accuracy: 0.9288\n",
      "Epoch: 106, error: 0.2283100033090578, train accuracy: 0.9342, test accuracy: 0.9288\n",
      "Epoch: 107, error: 0.22781931285268564, train accuracy: 0.9344166666666667, test accuracy: 0.9289\n",
      "Epoch: 108, error: 0.2273334194125147, train accuracy: 0.9345666666666667, test accuracy: 0.9293\n",
      "Epoch: 109, error: 0.22685253670931316, train accuracy: 0.9347333333333333, test accuracy: 0.9292\n",
      "Epoch: 110, error: 0.22637685819532233, train accuracy: 0.9349666666666666, test accuracy: 0.9292\n",
      "Epoch: 110, error: 0.22637685819532233, train accuracy: 0.9349666666666666, test accuracy: 0.9292\n",
      "Epoch: 111, error: 0.22590637615812845, train accuracy: 0.9351666666666667, test accuracy: 0.9293\n",
      "Epoch: 112, error: 0.22544105527848707, train accuracy: 0.9352, test accuracy: 0.9296\n",
      "Epoch: 113, error: 0.22498083356364837, train accuracy: 0.9353833333333333, test accuracy: 0.9298\n",
      "Epoch: 114, error: 0.22452562360659067, train accuracy: 0.9355, test accuracy: 0.9297\n",
      "Epoch: 115, error: 0.22407531413978427, train accuracy: 0.9357333333333333, test accuracy: 0.9299\n",
      "Epoch: 116, error: 0.22362977185175165, train accuracy: 0.9357166666666666, test accuracy: 0.9301\n",
      "Epoch: 117, error: 0.22318884343052237, train accuracy: 0.9355666666666667, test accuracy: 0.9302\n",
      "Epoch: 118, error: 0.2227523578637666, train accuracy: 0.9357166666666666, test accuracy: 0.9302\n",
      "Epoch: 119, error: 0.22232012895335226, train accuracy: 0.93585, test accuracy: 0.9301\n",
      "Epoch: 120, error: 0.2218919580467533, train accuracy: 0.93605, test accuracy: 0.93\n",
      "Epoch: 120, error: 0.2218919580467533, train accuracy: 0.93605, test accuracy: 0.93\n",
      "Epoch: 121, error: 0.22146763692637922, train accuracy: 0.93625, test accuracy: 0.9301\n",
      "Epoch: 122, error: 0.2210469508258193, train accuracy: 0.9363333333333334, test accuracy: 0.9302\n",
      "Epoch: 123, error: 0.22062948978645036, train accuracy: 0.9364833333333333, test accuracy: 0.9306\n",
      "Epoch: 124, error: 0.22021503401879394, train accuracy: 0.9365666666666667, test accuracy: 0.9308\n",
      "Epoch: 125, error: 0.21980333016045897, train accuracy: 0.9368333333333333, test accuracy: 0.9311\n",
      "Epoch: 126, error: 0.21939418246925033, train accuracy: 0.9369166666666666, test accuracy: 0.9315\n",
      "Epoch: 127, error: 0.21898761445937148, train accuracy: 0.9370666666666667, test accuracy: 0.9313\n",
      "Epoch: 128, error: 0.2185826215180637, train accuracy: 0.9372166666666667, test accuracy: 0.9316\n",
      "Epoch: 129, error: 0.2181796022829389, train accuracy: 0.9372, test accuracy: 0.9317\n",
      "Epoch: 130, error: 0.2177786019069347, train accuracy: 0.9374666666666667, test accuracy: 0.9319\n",
      "Epoch: 130, error: 0.2177786019069347, train accuracy: 0.9374666666666667, test accuracy: 0.9319\n",
      "Epoch: 131, error: 0.21737946153396828, train accuracy: 0.9375333333333333, test accuracy: 0.932\n",
      "Epoch: 132, error: 0.21698203599067092, train accuracy: 0.9375, test accuracy: 0.932\n",
      "Epoch: 133, error: 0.21658619415900915, train accuracy: 0.9376333333333333, test accuracy: 0.9321\n",
      "Epoch: 134, error: 0.21619181905065968, train accuracy: 0.9379166666666666, test accuracy: 0.9325\n",
      "Epoch: 135, error: 0.21579880758662406, train accuracy: 0.9380666666666667, test accuracy: 0.9327\n",
      "Epoch: 136, error: 0.2154070701258793, train accuracy: 0.9382, test accuracy: 0.9327\n",
      "Epoch: 137, error: 0.21501652976982127, train accuracy: 0.93825, test accuracy: 0.9328\n",
      "Epoch: 138, error: 0.2146271214994939, train accuracy: 0.9383333333333334, test accuracy: 0.9329\n",
      "Epoch: 139, error: 0.2142387912037173, train accuracy: 0.9384333333333333, test accuracy: 0.9334\n",
      "Epoch: 140, error: 0.2138514946492137, train accuracy: 0.9388, test accuracy: 0.9334\n",
      "Epoch: 140, error: 0.2138514946492137, train accuracy: 0.9388, test accuracy: 0.9334\n",
      "Epoch: 141, error: 0.21346519643321124, train accuracy: 0.9388166666666666, test accuracy: 0.9336\n",
      "Epoch: 142, error: 0.21307986894672915, train accuracy: 0.939, test accuracy: 0.9337\n",
      "Epoch: 143, error: 0.21269549136314012, train accuracy: 0.9390833333333334, test accuracy: 0.9336\n",
      "Epoch: 144, error: 0.2123120486995123, train accuracy: 0.93925, test accuracy: 0.9336\n",
      "Epoch: 145, error: 0.21192953097355033, train accuracy: 0.9393166666666667, test accuracy: 0.9338\n",
      "Epoch: 146, error: 0.21154793253191478, train accuracy: 0.93945, test accuracy: 0.9338\n",
      "Epoch: 147, error: 0.2111672516242409, train accuracy: 0.9396, test accuracy: 0.9341\n",
      "Epoch: 148, error: 0.21078749029341048, train accuracy: 0.9397833333333333, test accuracy: 0.9341\n",
      "Epoch: 149, error: 0.2104086546234806, train accuracy: 0.9398166666666666, test accuracy: 0.9341\n",
      "Epoch: 150, error: 0.2100307553384763, train accuracy: 0.93985, test accuracy: 0.9341\n",
      "Epoch: 150, error: 0.2100307553384763, train accuracy: 0.93985, test accuracy: 0.9341\n",
      "Epoch: 151, error: 0.20965380868064454, train accuracy: 0.9399666666666666, test accuracy: 0.9339\n",
      "Epoch: 152, error: 0.20927783747564183, train accuracy: 0.9401166666666667, test accuracy: 0.9341\n",
      "Epoch: 153, error: 0.20890287222503748, train accuracy: 0.94035, test accuracy: 0.934\n",
      "Epoch: 154, error: 0.208528952095718, train accuracy: 0.9403333333333334, test accuracy: 0.9342\n",
      "Epoch: 155, error: 0.20815612568687142, train accuracy: 0.9404166666666667, test accuracy: 0.9342\n",
      "Epoch: 156, error: 0.2077844514789344, train accuracy: 0.94045, test accuracy: 0.9343\n",
      "Epoch: 157, error: 0.20741399794059429, train accuracy: 0.9405333333333333, test accuracy: 0.9344\n",
      "Epoch: 158, error: 0.2070448432894058, train accuracy: 0.94065, test accuracy: 0.9343\n",
      "Epoch: 159, error: 0.20667707491979354, train accuracy: 0.94085, test accuracy: 0.9345\n",
      "Epoch: 160, error: 0.2063107885684211, train accuracy: 0.9410833333333334, test accuracy: 0.9349\n",
      "Epoch: 160, error: 0.2063107885684211, train accuracy: 0.9410833333333334, test accuracy: 0.9349\n",
      "Epoch: 161, error: 0.20594608728366323, train accuracy: 0.9412666666666667, test accuracy: 0.935\n",
      "Epoch: 162, error: 0.2055830802508538, train accuracy: 0.9414333333333333, test accuracy: 0.9352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163, error: 0.20522188154827647, train accuracy: 0.9415166666666667, test accuracy: 0.9349\n",
      "Epoch: 164, error: 0.20486248395481949, train accuracy: 0.9416666666666667, test accuracy: 0.9351\n",
      "Epoch: 165, error: 0.20450451145114068, train accuracy: 0.94175, test accuracy: 0.9352\n",
      "Epoch: 166, error: 0.2041487004044432, train accuracy: 0.9418166666666666, test accuracy: 0.9351\n",
      "Epoch: 167, error: 0.20379505220124453, train accuracy: 0.9417833333333333, test accuracy: 0.9349\n",
      "Epoch: 168, error: 0.20344374931262962, train accuracy: 0.9419166666666666, test accuracy: 0.935\n",
      "Epoch: 169, error: 0.2030949495752367, train accuracy: 0.94205, test accuracy: 0.9352\n",
      "Epoch: 170, error: 0.20274876817712195, train accuracy: 0.9422666666666667, test accuracy: 0.9356\n",
      "Epoch: 170, error: 0.20274876817712195, train accuracy: 0.9422666666666667, test accuracy: 0.9356\n",
      "Epoch: 171, error: 0.20240531703772405, train accuracy: 0.9422666666666667, test accuracy: 0.9356\n",
      "Epoch: 172, error: 0.20206470415039102, train accuracy: 0.9423333333333334, test accuracy: 0.9357\n",
      "Epoch: 173, error: 0.20172703298296807, train accuracy: 0.9423333333333334, test accuracy: 0.936\n",
      "Epoch: 174, error: 0.20139240192822258, train accuracy: 0.9423666666666667, test accuracy: 0.936\n",
      "Epoch: 175, error: 0.2010609037989912, train accuracy: 0.9425333333333333, test accuracy: 0.9362\n",
      "Epoch: 176, error: 0.20073262536652658, train accuracy: 0.94265, test accuracy: 0.9363\n",
      "Epoch: 177, error: 0.2004076469441266, train accuracy: 0.9426, test accuracy: 0.9363\n",
      "Epoch: 178, error: 0.20008604202132077, train accuracy: 0.9426833333333333, test accuracy: 0.9366\n",
      "Epoch: 179, error: 0.19976787695636491, train accuracy: 0.9426666666666667, test accuracy: 0.9364\n",
      "Epoch: 180, error: 0.19945321073633313, train accuracy: 0.9426666666666667, test accuracy: 0.9361\n",
      "Epoch: 180, error: 0.19945321073633313, train accuracy: 0.9426666666666667, test accuracy: 0.9361\n",
      "Epoch: 181, error: 0.19914209481458703, train accuracy: 0.94285, test accuracy: 0.9359\n",
      "Epoch: 182, error: 0.19883457303670266, train accuracy: 0.9429833333333333, test accuracy: 0.936\n",
      "Epoch: 183, error: 0.19853068166112287, train accuracy: 0.9431333333333334, test accuracy: 0.9363\n",
      "Epoch: 184, error: 0.1982304494568992, train accuracy: 0.94315, test accuracy: 0.9365\n",
      "Epoch: 185, error: 0.19793389794566565, train accuracy: 0.9433166666666667, test accuracy: 0.9366\n",
      "Epoch: 186, error: 0.19764104171051158, train accuracy: 0.9433833333333334, test accuracy: 0.9368\n",
      "Epoch: 187, error: 0.1973518888120285, train accuracy: 0.9433833333333334, test accuracy: 0.937\n",
      "Epoch: 188, error: 0.19706644126405692, train accuracy: 0.9434666666666667, test accuracy: 0.9369\n",
      "Epoch: 189, error: 0.19678469562307235, train accuracy: 0.94355, test accuracy: 0.937\n",
      "Epoch: 190, error: 0.1965066435998824, train accuracy: 0.9435833333333333, test accuracy: 0.937\n",
      "Epoch: 190, error: 0.1965066435998824, train accuracy: 0.9435833333333333, test accuracy: 0.937\n",
      "Epoch: 191, error: 0.19623227272827964, train accuracy: 0.9436166666666667, test accuracy: 0.937\n",
      "Epoch: 192, error: 0.1959608963558347, train accuracy: 0.9436833333333333, test accuracy: 0.9373\n",
      "Epoch: 193, error: 0.19569221067675605, train accuracy: 0.9437333333333333, test accuracy: 0.9374\n",
      "Epoch: 194, error: 0.19542714602312283, train accuracy: 0.94375, test accuracy: 0.9375\n",
      "Epoch: 195, error: 0.19516568203531015, train accuracy: 0.9438166666666666, test accuracy: 0.9375\n",
      "Epoch: 196, error: 0.19490779761492108, train accuracy: 0.9439, test accuracy: 0.9373\n",
      "Epoch: 197, error: 0.1946534715255093, train accuracy: 0.9439166666666666, test accuracy: 0.9378\n",
      "Epoch: 198, error: 0.19440268294019472, train accuracy: 0.9440166666666666, test accuracy: 0.9379\n",
      "Epoch: 199, error: 0.19415541193782163, train accuracy: 0.944, test accuracy: 0.9379\n",
      "Epoch: 200, error: 0.1939116399715224, train accuracy: 0.9441333333333334, test accuracy: 0.938\n",
      "Epoch: 200, error: 0.1939116399715224, train accuracy: 0.9441333333333334, test accuracy: 0.938\n",
      "Epoch: 201, error: 0.19367130228984059, train accuracy: 0.9441666666666667, test accuracy: 0.9383\n",
      "Epoch: 202, error: 0.19343402408662977, train accuracy: 0.9443333333333334, test accuracy: 0.9385\n",
      "Epoch: 203, error: 0.19320020279613367, train accuracy: 0.9444666666666667, test accuracy: 0.9384\n",
      "Epoch: 204, error: 0.19296983004633883, train accuracy: 0.9445666666666667, test accuracy: 0.9388\n",
      "Epoch: 205, error: 0.1927429008817658, train accuracy: 0.9446, test accuracy: 0.9385\n",
      "Epoch: 206, error: 0.19251941414685222, train accuracy: 0.9447, test accuracy: 0.9385\n",
      "Epoch: 207, error: 0.19229937284962545, train accuracy: 0.94475, test accuracy: 0.9386\n",
      "Epoch: 208, error: 0.19208278449200478, train accuracy: 0.9447333333333333, test accuracy: 0.9388\n",
      "Epoch: 209, error: 0.19186966134789693, train accuracy: 0.9448166666666666, test accuracy: 0.9389\n",
      "Epoch: 210, error: 0.19166002067282195, train accuracy: 0.94485, test accuracy: 0.939\n",
      "Epoch: 210, error: 0.19166002067282195, train accuracy: 0.94485, test accuracy: 0.939\n",
      "Epoch: 211, error: 0.19145388478137973, train accuracy: 0.94505, test accuracy: 0.9394\n",
      "Epoch: 212, error: 0.19125128107825354, train accuracy: 0.94495, test accuracy: 0.9393\n",
      "Epoch: 213, error: 0.19105224197162354, train accuracy: 0.9450333333333333, test accuracy: 0.9393\n",
      "Epoch: 214, error: 0.1908568047260584, train accuracy: 0.9451333333333334, test accuracy: 0.9391\n",
      "Epoch: 215, error: 0.19066501128358102, train accuracy: 0.9451666666666667, test accuracy: 0.9389\n",
      "Epoch: 216, error: 0.1904769080598114, train accuracy: 0.9451833333333334, test accuracy: 0.9388\n",
      "Epoch: 217, error: 0.19029254578484178, train accuracy: 0.94525, test accuracy: 0.9386\n",
      "Epoch: 218, error: 0.19011197933907106, train accuracy: 0.9451833333333334, test accuracy: 0.9385\n",
      "Epoch: 219, error: 0.18993526756441742, train accuracy: 0.9453, test accuracy: 0.9386\n",
      "Epoch: 220, error: 0.18976247302105645, train accuracy: 0.94525, test accuracy: 0.9385\n",
      "Epoch: 220, error: 0.18976247302105645, train accuracy: 0.94525, test accuracy: 0.9385\n",
      "Epoch: 221, error: 0.18959366159601176, train accuracy: 0.9452, test accuracy: 0.939\n",
      "Epoch: 222, error: 0.1894289019058167, train accuracy: 0.9452333333333334, test accuracy: 0.9389\n",
      "Epoch: 223, error: 0.18926826441168842, train accuracy: 0.9454, test accuracy: 0.9389\n",
      "Epoch: 224, error: 0.18911182028274306, train accuracy: 0.9453, test accuracy: 0.9389\n",
      "Epoch: 225, error: 0.18895963996941836, train accuracy: 0.9453, test accuracy: 0.939\n",
      "Epoch: 226, error: 0.1888112007497406, train accuracy: 0.9453333333333334, test accuracy: 0.939\n",
      "Epoch: 227, error: 0.1886671539287469, train accuracy: 0.9454, test accuracy: 0.939\n",
      "Epoch: 228, error: 0.18852759581996245, train accuracy: 0.9454166666666667, test accuracy: 0.9392\n",
      "Epoch: 229, error: 0.1883925765929361, train accuracy: 0.9454166666666667, test accuracy: 0.9393\n",
      "Epoch: 230, error: 0.1882621370306623, train accuracy: 0.9455333333333333, test accuracy: 0.9394\n",
      "Epoch: 230, error: 0.1882621370306623, train accuracy: 0.9455333333333333, test accuracy: 0.9394\n",
      "Epoch: 231, error: 0.18813630710322435, train accuracy: 0.9455333333333333, test accuracy: 0.9394\n",
      "Epoch: 232, error: 0.18801510450175496, train accuracy: 0.9455166666666667, test accuracy: 0.9397\n",
      "Epoch: 233, error: 0.18789853307462, train accuracy: 0.94565, test accuracy: 0.9397\n",
      "Epoch: 234, error: 0.18778658112527996, train accuracy: 0.9456666666666667, test accuracy: 0.9397\n",
      "Epoch: 235, error: 0.187679219591168, train accuracy: 0.94575, test accuracy: 0.9393\n",
      "Epoch: 236, error: 0.18757640021569452, train accuracy: 0.9459166666666666, test accuracy: 0.939\n",
      "Epoch: 237, error: 0.18747805381965454, train accuracy: 0.94605, test accuracy: 0.9389\n"
     ]
    }
   ],
   "source": [
    "W, b = create_weights(architecture)\n",
    "batch_size = 1000\n",
    "W, b, errors, acc_train, acc_test,test_loss = train(X_train, y_train,X_test,y_test, num_classes =10, W = W, b=b,f=f,_lambda = 0.01 ,alpha=0.5 ,max_delta_error =1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:03:19.902932Z",
     "start_time": "2020-04-02T14:03:19.673520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(errors, label='Loss on train DS')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18834417351795993\n"
     ]
    }
   ],
   "source": [
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:08:45.594232Z",
     "start_time": "2020-04-02T14:08:45.419907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a01f705848>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# acc_train, acc_test\n",
    "plt.plot(acc_train, label='Acc train')\n",
    "plt.plot(acc_test, label='Acc test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:12:22.914348Z",
     "start_time": "2020-04-02T05:12:22.885426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9446\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on test set: {accuracy(X_test, y_test, W,b,f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
