{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taraburca Radu grupa 383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.688762Z",
     "start_time": "2020-04-15T05:32:33.683775Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.703722Z",
     "start_time": "2020-04-15T05:32:33.694747Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_file(path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Loads the data from the file stored at :param path: and returns the \n",
    "    input values and the class labels.\n",
    "    :param path: path of a CVS file with data\n",
    "    :return: a tuple containing the input matrix of shape (n, p) and a line \n",
    "    vector with the m class labels in {0, ..., 9}\n",
    "    \"\"\"\n",
    "    # citire date sin fisierul dat de path\n",
    "    df = pd.read_csv(path,header=None)\n",
    "    X = df.values[:,1:].T\n",
    "    y = df.values[:,0].reshape(len(df),1).T\n",
    "    assert X.ndim ==  2, 'Matrix required for input values'\n",
    "    assert y.ndim == 2, 'Column matrix required for labels'\n",
    "    assert y.shape == (1, X.shape[1]), 'Same number of lines is required'\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:33.710703Z",
     "start_time": "2020-04-15T05:32:33.706715Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = './data/mnist_train.csv'\n",
    "path_test = './data/mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.182596Z",
     "start_time": "2020-04-15T05:32:33.713696Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_file(path_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "assert y_train.shape == (1, 60000)\n",
    "\n",
    "X_test, y_test = load_file(path_test)\n",
    "assert X_test.shape == (784, 10000)\n",
    "assert y_test.shape == (1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.194562Z",
     "start_time": "2020-04-15T05:32:38.184589Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_values(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Scales the values to range [0, 1].\n",
    "    :param X: an (m, n) matrix with values between 0 and 255.\n",
    "    :return: an (m, n) matrix containing values of :param X: scaled in [0, 1]\n",
    "    \"\"\"\n",
    "    result = X/255\n",
    "    assert 0 <= np.min(result) <= np.max(result) <= 1, 'Scaled values should be in [0, 1]'\n",
    "    assert X.shape == result.shape, 'Scaling preserves shape'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.531663Z",
     "start_time": "2020-04-15T05:32:38.203540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = scale_values(X_train)\n",
    "assert X_train.shape == (784, 60000)\n",
    "X_test = scale_values(X_test)\n",
    "assert X_test.shape == (784, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T15:41:07.997557Z",
     "start_time": "2019-11-24T15:41:07.991110Z"
    }
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.541636Z",
     "start_time": "2020-04-15T05:32:38.535651Z"
    }
   },
   "outputs": [],
   "source": [
    "m = 10 # number of classes\n",
    "n, p = X_train.shape\n",
    "architecture = [n, 100, m] # list: [input_size, hidden1, hidden2, ..., output_size]\n",
    "\n",
    "assert len(architecture) >= 3, 'At least one hidden layer'\n",
    "assert architecture[0] == n\n",
    "assert architecture[-1] == m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderile sunt initializate conform strategiei lui Xavier Glorot. Pentru o matrice de ponderi $W^{[l]}$ de forma $n_{l} \\times n_{l-1}$, ponderile pot fi initializate cu o distributie uniforma in intervalul \n",
    "$$\n",
    "\\left[-\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}, +\\frac{\\sqrt{6}}{\\sqrt{n_{l} + n_{l-1}}}\\right]\n",
    "$$\n",
    "\n",
    "Ponderile de bias se obisnuiesc a se initializa cu 0; intializarea aleatoare a ponderilor W este considerata suficienta pentru a obtine spargerea simetriei.\n",
    "\n",
    "Ref: [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.567564Z",
     "start_time": "2020-04-15T05:32:38.545624Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_weights(architecture: List[int], init_type:str='glorot_uniform') -> Tuple[List[np.array], List[np.array]]:\n",
    "    \"\"\"Creates the list of weights and biases for the given architecture.\n",
    "    :param architecture: list of number of nodes in each layer \n",
    "    (including input and ouotput layers)\n",
    "    :param init_type: name of initialization parameter. Defaults to \n",
    "    'glorot_uniform', add other supported initializtion strategies.\n",
    "    :return: a tuple containing: list of weight matrices W, a list of bias \n",
    "    column vectors. The two lists have the same numer of elements, number of \n",
    "    layers - 1.\n",
    "    \"\"\"\n",
    "    L = len(architecture)\n",
    "    W, b = [], []\n",
    "    # initializare de ponderi\n",
    "    for n_lplus1, nl in zip(architecture[1:], architecture[:-1]):\n",
    "        W.append(\n",
    "            np.random.uniform(\n",
    "                -np.sqrt(6)/np.sqrt(n_lplus1+ nl),\n",
    "                np.sqrt(6)/np.sqrt(n_lplus1+ nl),\n",
    "                n_lplus1*nl).reshape(n_lplus1,nl),\n",
    "        )\n",
    "        #... scrieti cod\n",
    "    for n_l in architecture[1:]:\n",
    "        b.append(np.zeros_like(np.arange(n_l)).reshape(n_l, 1))# scrieti cod\n",
    "    assert len(W) == len(b) == L-1\n",
    "    for i, w in enumerate(W):\n",
    "        assert w.shape == (architecture[i+1], architecture[i]), f'Shape of W[{i}] should be ({L[i+1], L[i]})'\n",
    "    for i, _b in enumerate(b):\n",
    "        assert _b.shape == (architecture[i+1], 1), f'Shape of b[{i}] should be ({L[i+1]}, 1)'\n",
    "    if init_type == 'glorot_uniform':\n",
    "        for i, w in enumerate(W):\n",
    "            w_shape_sum = np.sum(w.shape)\n",
    "            assert -np.sqrt(6)/np.sqrt(w_shape_sum) <= np.min(w) <= np.sqrt(6)/np.sqrt(w_shape_sum), f\"Values of W[{i}] should be according to Glorot's initialization\"\n",
    "        for i, _b in enumerate(b):\n",
    "            assert 0 == np.min(_b) == np.min(_b) == 0, f\"Values of b[{i}] should be initialized to 0\"\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.584519Z",
     "start_time": "2020-04-15T05:32:38.569559Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def derivate_sigmoid(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the sigmoid activation function\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the tanh activation function\"\"\"\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "def derivate_tanh(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives for the tanh activation function\"\"\"\n",
    "    return 1 - tanh(z) ** 2\n",
    "\n",
    "def ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the rectified linear unit activation function\"\"\"\n",
    "    return np.where(z > 0, [z, 0])\n",
    "\n",
    "def derivative_ReLU(z: np.array) -> np.array:\n",
    "    \"\"\"Computes the derivatives of the rectified linear unit activation function\"\"\"\n",
    "    return np.where(z > 0, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.596496Z",
     "start_time": "2020-04-15T05:32:38.589506Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z, axis=0):\n",
    "    \"\"\"Applies softmax to a matrix z.\n",
    "    :param z: np.array of shape (m, k)\n",
    "    \"\"\"\n",
    "    # scrieti cod, posibil mai multe linii\n",
    "    result = np.exp(z) / np.sum(np.exp(z), axis=axis)\n",
    "    assert np.allclose(np.sum(result, axis=axis), 1.0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.609453Z",
     "start_time": "2020-04-15T05:32:38.599481Z"
    }
   },
   "outputs": [],
   "source": [
    "W, b = create_weights(architecture=architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T15:54:14.739424Z",
     "start_time": "2020-04-15T15:54:14.320545Z"
    }
   },
   "outputs": [],
   "source": [
    "def can_multiply(a:np.array, b:np.array) -> bool:\n",
    "    return a.ndim == b.ndim == 2 and a.shape[1] == b.shape[0]\n",
    "\n",
    "def can_multiply_hadamard(a:np.array, b:np.array) -> bool:\n",
    "    return a.shape == b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=[]\n",
    "A=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.636381Z",
     "start_time": "2020-04-15T05:32:38.624413Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(X:np.array, W:List[np.array], b:List[np.array], f:List[Callable]) -> np.array:\n",
    "    \"\"\"Computes the output produced by the MLP for the given input X\n",
    "    :param X: np.array of shape (n, p). Each column of X is a datum from a set.\n",
    "    :param W: a list of weight matrices\n",
    "    :param b: a list of bias columns\n",
    "    :param f: a list of activation functions\n",
    "    :return: a matrix of output values produced by MLP, of shape: number of \n",
    "    predicted outputs (e.g. classes), number of input vectors p\n",
    "    \"\"\"\n",
    "    assert len(W) == len(b) == len(f)\n",
    "    p = X.shape[1]\n",
    "    a = X\n",
    "    for i, (_w, _b, _f) in enumerate(zip(W, b, f)):\n",
    "        # variabila i poate fi folosita pentru debug\n",
    "        assert can_multiply(_w, a)\n",
    "        z = np.dot(_w, a) + _b\n",
    "        Z=z\n",
    "        assert z.shape == (_w.shape[0], p)\n",
    "        a =_f(z)\n",
    "        A=a\n",
    "        assert a.shape == z.shape\n",
    "    assert a.shape == (W[-1].shape[0], p)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:38.852801Z",
     "start_time": "2020-04-15T05:32:38.639373Z"
    }
   },
   "outputs": [],
   "source": [
    "# f[0] = functia de activare pe primul strat ascuns; \n",
    "# f[1] = functia de activare pe al doilea strat ascuns etc.\n",
    "f = [sigmoid, softmax] \n",
    "y_hat = model(X_train, W, b, f)\n",
    "\n",
    "assert y_hat.shape == (m, p)\n",
    "assert np.allclose(y_hat.sum(axis=0), np.ones(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(W[0])\n",
    "# arg3 = np.sum(np.sum(np.square(W[1]), axis = 0))\n",
    "# arg2 = np.sum(np.sum(np.square(W[0]), axis = 0))\n",
    "\n",
    "# print(arg2+arg3)\n",
    "# np.sum([np.linalg.norm(w)**2 for w in W])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T05:32:44.535803Z",
     "start_time": "2020-04-15T05:32:44.527825Z"
    }
   },
   "outputs": [],
   "source": [
    "def J(X, y, W, b, f, num_classes=10, _lambda=0.01):\n",
    "    \"\"\"Computes the error function for MLP\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k)\n",
    "    :param W: list pf MLPs weights\n",
    "    :param b: list pf MLPs biases\n",
    "    :return: loss values, composed of cross entropy + penalty term\n",
    "    \"\"\"\n",
    "    p = X.shape[1]\n",
    "    EPS = 1e-5\n",
    "    # computes a one hot encoding for the given classes:\n",
    "    # if y[i]=c, 0 <= c <= 9 (here), then column i in one_hot_encoding is filled\n",
    "    # in with 0, excepting line c where one finds value 1\n",
    "    if y.shape[0] == 1 :\n",
    "        one_hot_encoding = np.zeros((p,num_classes))\n",
    "        one_hot_encoding[np.arange(y.shape[1]), y] = 1\n",
    "        one_hot_encoding = one_hot_encoding.T\n",
    "        y= one_hot_encoding\n",
    "        assert np.allclose(one_hot_encoding.sum(axis=0), np.ones(p))    \n",
    "    assert np.allclose(y.sum(axis=0), np.ones(p))   \n",
    "    predicted = model(X, W, b, f)\n",
    "    predicted = np.clip(predicted, EPS, 1-EPS)\n",
    "    loss1 = -(1.0 / p) *np.sum(np.multiply(np.log(predicted),y)) # scrieti cod \n",
    "    loss2 = (_lambda/(2 * p))*np.sum([np.linalg.norm(w)**2 for w in W])\n",
    "    return loss1 + loss2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.074986Z",
     "start_time": "2020-04-02T05:08:15.069005Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(X:np.array, y:np.array, W: List[np.array], b: List[np.array], f:List[Callable]) -> float:\n",
    "    \"\"\"Computes the accuracy on a given input dataset X, with ground truth y\n",
    "    :param X: np.array of shape (n, k)\n",
    "    :param y: np.array of shape (1, k); each value is the index of a class\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activation functions. the last one must be softmax\n",
    "    :return: ratio between correctly classified vectors and total number of cases\n",
    "    \"\"\"\n",
    "    y_hat = model(X, W, b, f)\n",
    "    y_predicted = y_hat == y_hat.max()\n",
    "    return (y_predicted == y).sum() / X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def back_propagation(X, y, W, b, f, num_classes=10, _lambda=0.01,alpha= 0.01):\n",
    "#     print(m,\" \",num_classes)\n",
    "#     dW=np.zeros((m,num_classes))\n",
    "#     db=np.zeros((m,1))\n",
    "#     dW, db = create_weights(architecture=architecture)\n",
    "#     y_hat = model(X, W, b, f)\n",
    "#     one_hot_encoding = np.zeros((m, X.shape[1]))\n",
    "#     one_hot_encoding[np.arange(y.shape[0]),y[np.arange(y.shape[0])]]=1\n",
    "#     p = X.shape[1]\n",
    "#     a = X\n",
    "#     arg=one_hot_encoding-y_hat\n",
    "# #     deltas = [None] * len(a)\n",
    "# #     deltas[-1] =  (-1 ) * (np.dot(arg,np.transpose(a)))\n",
    "    \n",
    "    \n",
    "#     for i, (_w, _b, _f) in enumerate(zip(W, b, f)):\n",
    "#         z = np.dot(_w, a) + _b\n",
    "#         a =_f(z)\n",
    "\n",
    "#         loss1 = (-1 ) * (np.dot(arg,np.transpose(a)))\n",
    "#     loss1 =np.dot(np.dot(np.transpose(_w),loss1),a)\n",
    "#     dPW = np.dot(loss1,np.transpose(a))\n",
    "#     dPb = loss1\n",
    "# #     loss2 = [w+dPW for w in dW]\n",
    "\n",
    "# #     for i, _b in enumerate(db):\n",
    "# #         print(_b.shape[0])\n",
    "# #         print(dPb.shape[0])\n",
    "# #         _b=_b+dPb\n",
    "    \n",
    "# #     for i, (_w, _b, _f) in enumerate(zip(dW, b, f)):\n",
    "# #     dW=dW+dPW\n",
    "# #         loss1 = (-1 ) * (np.dot(,np.transpose(a)))\n",
    "\n",
    "# #     W= W-alpha*(((1/p)*np.array(dW))+_lambda*W)\n",
    "#     for i, w in enumerate(W):\n",
    "#         arg1=(1/p)*np.array(dW)\n",
    "# #         print(arg1[0].shape[1])\n",
    "#         arg2=_lambda*np.array(w)\n",
    "# #         arg3=arg1[1]+arg2\n",
    "#         w=w-alpha*(arg2)\n",
    "#     b=b-alpha*((1/p)*np.array(db))\n",
    "\n",
    "#     return dW,db   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X,y, W, b,f,num_classes=10,_lambda=0.01,alpha=0.01):\n",
    "    batch_loss = 0\n",
    "    for it in range(int(X.shape[1] / batch_size)):\n",
    "            X_batch = X[:, it * batch_size:(it + 1) * batch_size]\n",
    "\n",
    "            one_hot_encoding = np.zeros((X.shape[1], 10))\n",
    "            one_hot_encoding[np.arange(y.shape[1]), y] = 1\n",
    "            one_hot_encoding = one_hot_encoding.T\n",
    "            y_batch = one_hot_encoding[:, it * batch_size:(it + 1) * batch_size]\n",
    "\n",
    "            error = J(X_batch, y_batch, W, b, f, num_classes, _lambda)\n",
    "            batch_loss += error\n",
    "\n",
    "            y_hat = model(X_batch, W, b, f)\n",
    "            \n",
    "            z1 = np.dot(W[0], X_batch) + b[0]\n",
    "            a1 = f[0](z1)\n",
    "    \n",
    "            delta2 = (1.0 / X_batch.shape[1]) * (y_hat - y_batch)\n",
    "            delta_theta2 = np.dot(a1, delta2.T) + (_lambda / X_batch.shape[1]) * W[1].T\n",
    "            delta_b2 = np.sum(delta2, axis=1, keepdims=True)\n",
    "            delta1 = np.dot(W[1].T, delta2) * derivate_sigmoid(a1)\n",
    "\n",
    "            delta_theta1 = np.dot(X_batch, delta1.T) + (_lambda / X_batch.shape[1]) * W[0].T\n",
    "            delta_b1 = np.sum(delta1, axis=1, keepdims=True)\n",
    "            \n",
    "            \n",
    "\n",
    "            W[1] = W[1] - alpha * delta_theta2.T\n",
    "            b[1] = b[1] - alpha * delta_b2\n",
    "            W[0] = W[0] - alpha * delta_theta1.T\n",
    "            b[0] = b[0] - alpha * delta_b1\n",
    "\n",
    "    return W,b\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:08:15.098922Z",
     "start_time": "2020-04-02T05:08:15.078976Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array, num_classes, W: List[np.array], b:List[np.array], f:List[Callable], _lambda: float, alpha: float, max_delta_error:float=1e-4) -> Tuple[List[np.array], List[np.array], List[float], List[float], List[float]]:\n",
    "    \"\"\"Runs the training on the training dataset (X, y). Stops when  \n",
    "    difference between  two succesive error values is lower than :param max_delta_error:\n",
    "    :param X_train: np.array of shape (n, k), with training cases. Each column is a training case\n",
    "    :param y_train: np.array of shape (1, k), containing labels (0=class 0, ...)\n",
    "    :param X_test: np.array of shape (n, l), with test cases. Each column is a test vector\n",
    "    :param y_test: np.array of shape (1, l), containing labels (0=class 0, ...)\n",
    "    :param num_classes: number of classes\n",
    "    :param W: list of MLP's weights\n",
    "    :param b: list of MLP's biases\n",
    "    :param f: list of activations functions; the last one must be softmax\n",
    "    :param _lambda: coefficient >= for the L2 penalty term\n",
    "    :param alpha: > 0, learning rate\n",
    "    :max_delta_error: >0, a threshold for max absolute difference of succesive loss values\n",
    "    :return: a tuple consisting of: list of weight matrices, list of biases, list of errors computed at each epoch on training set, 2 lists of accuracies on training and on test set at each epoch\n",
    "    \"\"\"\n",
    "    errors = [J(X_train, y_train, W, b, f, num_classes, _lambda)]\n",
    "    acc_train = [accuracy(X_train, y_train, W, b, f)]\n",
    "    acc_test = [accuracy(X_test, y_test, W, b, f)]\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        epoch += 1\n",
    "        # actualizare ponderi si biases W, b pentru fiecare pereche de date din setul de instruire *_test\n",
    "        error = J(X_test, y_test, W, b, f, num_classes, _lambda)\n",
    "        W, b=back_propagation(X_test, y_test, W, b,f,num_classes, _lambda,alpha)\n",
    "        # scrieti cod\n",
    "        errors.append(error)\n",
    "        train_acc =accuracy(X_train, y_train, W, b, f)\n",
    "        acc_train.append(train_acc)\n",
    "        test_acc = accuracy(X_test, y_test, W, b, f)\n",
    "        acc_test.append(test_acc)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, error: {error}, train accuracy: {train_acc}, test accuracy: {test_acc}')\n",
    "        if np.abs(errors[-1] - errors[-2]) < max_delta_error:\n",
    "            break\n",
    "        \n",
    "        # plot de valore de eroare pe train si pe test\n",
    "    return W, b, errors, acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T13:44:41.944041Z",
     "start_time": "2020-04-02T05:52:03.345797Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, error: 1.3452210020214204, train accuracy: 0.98715, test accuracy: 0.9799\n",
      "Epoch: 20, error: 0.858589669148649, train accuracy: 0.98715, test accuracy: 0.9799\n",
      "Epoch: 30, error: 0.6618354353205518, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 40, error: 0.5606015359082701, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 50, error: 0.4989540909613809, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 60, error: 0.45711890838438146, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 70, error: 0.4266078563239026, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 80, error: 0.40321402152290214, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 90, error: 0.3846119344533532, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 100, error: 0.36940482861235535, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 110, error: 0.3566987932536675, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 120, error: 0.34589289918506194, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 130, error: 0.3365671288017336, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 140, error: 0.3284184935524651, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 150, error: 0.32122263081427643, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 160, error: 0.31480968738314746, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 170, error: 0.30904861391530974, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 180, error: 0.30383661769721726, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 190, error: 0.29909189062211733, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 200, error: 0.2947484796703314, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 210, error: 0.29075259572923895, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 220, error: 0.2870599102075604, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 230, error: 0.28363354376130023, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 240, error: 0.28044254866602, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 250, error: 0.2774607489293927, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 260, error: 0.2746658433990564, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 270, error: 0.2720387047484617, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 280, error: 0.26956282610255267, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 290, error: 0.26722388017555343, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 300, error: 0.2650093650309517, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 310, error: 0.2629083171694304, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 320, error: 0.26091107741694797, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 330, error: 0.2590090985682405, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 340, error: 0.25719478631264314, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 350, error: 0.25546136688612675, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 360, error: 0.25380277633539355, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 370, error: 0.252213567401692, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 380, error: 0.25068883074736154, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 390, error: 0.2492241280255605, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 400, error: 0.24781543497184275, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 410, error: 0.24645909249662754, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 420, error: 0.2451517646787435, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 430, error: 0.24389040251102673, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 440, error: 0.2426722124995037, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 450, error: 0.24149462937447033, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 460, error: 0.24035529229839667, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 470, error: 0.2392520240584025, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 480, error: 0.23818281281494647, train accuracy: 0.9871666666666666, test accuracy: 0.98\n",
      "Epoch: 490, error: 0.2371457960471313, train accuracy: 0.9871666666666666, test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "W, b = create_weights(architecture)\n",
    "batch_size = 1000\n",
    "W, b, errors, acc_train, acc_test = train(X_train, y_train, X_test, y_test, 10, W, b, f, 0.01, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:03:19.902932Z",
     "start_time": "2020-04-02T14:03:19.673520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(errors, label='Loss on train DS')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:08:45.594232Z",
     "start_time": "2020-04-02T14:08:45.419907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x297dedd2748>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# acc_train, acc_test\n",
    "plt.plot(acc_train, label='Acc train')\n",
    "plt.plot(acc_test, label='Acc test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T05:12:22.914348Z",
     "start_time": "2020-04-02T05:12:22.885426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on test set: {accuracy(X_test, y_test, W,b,f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
